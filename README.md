# VA tools

These are tools I have written to do my work more effectively at the VA.

## Usage: process_contracts_v3.py

This script processes PDF contracts found in the `azure_pdfs` directory, extracts text, analyzes them using an LLM, and outputs the results to `contract_analysis.csv`.

**Basic Usage:**

```bash
python process_contracts_v3.py
```

**Environment Variables:**

Make sure you have a `.env.local` file in the same directory with the necessary API keys:

*   `openai_api_key`: Your Azure OpenAI API key (used by default).
*   `openai_api_key_smart`: Your standard OpenAI API key (used with `--smart-mode`).

**Command-line Options:**

*   `--smart-mode`: Use the standard OpenAI client (`o3-mini` model) instead of the default Azure OpenAI client (`gpt-4o` model). Requires `openai_api_key_smart` to be set in `.env.local`.
*   `--second-pass-only`: Skip the initial data extraction (pass 1) and only perform the munchable analysis (pass 2) on existing results in `contract_analysis.csv`.
*   `--test-mode`: Run the script on a small batch of 3 files for testing purposes.
*   `--batch-size <NUMBER>`: Specify the number of contracts to process in each batch (default: 25).

**Example:**

Run in smart mode with a batch size of 10:

```bash
python process_contracts_v3.py --smart-mode --batch-size 10
```

Run only the second pass analysis:

```bash
python process_contracts_v3.py --second-pass-only
```

## Usage: analyze_contracts.py

This script reads the `contract_analysis.csv` file generated by `process_contracts_v3.py`, cleans currency data, and performs analysis to calculate total contract values, FY25 values, and vendor rankings. It outputs the analysis both to the console and to a timestamped text file (e.g., `contract_analysis_YYYYMMDD_HHMMSS.txt`).

**Basic Usage:**

```bash
python analyze_contracts.py
```

The script reads `contract_analysis.csv` from the current directory and outputs the analysis file to the same directory. It first provides an analysis of all contracts and then a separate analysis for contracts marked as "munchable".

## Usage: analyze_eos.py

This script analyzes internal PDF memos found in the `pdfs` directory for compliance with specific Executive Orders (related to DEI, gender identity, COVID policies, climate initiatives, WHO partnerships). It uses an LLM to score memos based on compliance criteria and outputs detailed results to `memo_analysis.csv`. Memos flagged as potentially non-compliant (score >= 5) are copied to the `flagged_memos` directory.

**Basic Usage:**

```bash
python analyze_eos.py
```

**Environment Variables:**

Ensure you have a `.env.local` file with the necessary API key:

*   `openai_api_key`: Your Azure OpenAI API key.

**Command-line Options:**

*   `--second-pass-only`: Skip the initial data extraction and only perform the detailed compliance analysis on existing results in `memo_analysis.csv`.
*   `--test-mode`: Run the script on a small batch of 3 files for testing purposes.

**Example:**

Run only the second pass analysis in test mode:

```bash
python analyze_eos.py --second-pass-only --test-mode
```

## Usage: download_azure_pdfs.py

This script connects to an Azure Blob Storage container and downloads all PDF files found within it to a local directory named `azure_pdfs`. It checks for existing files and only downloads if the local file is missing or incomplete.

**Setup:**

1.  Ensure you have a `.env.local` file in the same directory.
2.  Add the necessary Azure Blob Storage SAS token to the `.env.local` file:
    ```
    SAS_TOKEN="your_sas_token_here"
    ```

**Basic Usage:**

```bash
python download_azure_pdfs.py
```

The script will log the download progress and output the downloaded files to the `azure_pdfs` directory in the current working directory.
